# Projeto: Scraper Judicial com Backup AutomÃ¡tico e IntegraÃ§Ã£o com PostgreSQL

## VisÃ£o Geral

Este projeto realiza **web scraping avanÃ§ado** no site do **Tribunal de JustiÃ§a de SÃ£o Paulo (TJSP)**, extraindo e persistindo dados estruturados de processos judiciais. Toda a automaÃ§Ã£o estÃ¡ conectada a um banco **PostgreSQL**, com suporte a **backup inteligente em Excel** em caso de falha, e recuperaÃ§Ã£o automÃ¡tica de dados ao reiniciar o sistema.

> Foco em confiabilidade, rastreabilidade e automaÃ§Ã£o de ponta a ponta.

## OBS: O projeto foi feico em curto periodo de tempo.

---

## Funcionalidades

* ğŸ“„ Consulta de processos por **nome completo**, **CPF** ou **RG**;
* ğŸ” PaginaÃ§Ã£o e scraping de mÃºltiplas pÃ¡ginas de resultados;
* ğŸ§¾ Coleta de dados como: nÃºmero do processo, foro, vara, classe, assunto e datas;
* ğŸ—ƒï¸ Estrutura relacional com mÃºltiplas tabelas:

  * `pesquisa`, `pesquisa_spv`, `lote`, `lote_pesquisa`, `estado`, `servico`
* ğŸ’¥ Backup automÃ¡tico `.xlsx` em caso de falha na gravaÃ§Ã£o dos dados;
* ğŸ” Reprocessamento de backups pendentes antes de executar novo scraping;
* ğŸ”„ Suporte a atualizaÃ§Ã£o ou ignorar dados jÃ¡ existentes (via `.env`).

---

## Como Executar

### 1. Clonar o repositÃ³rio e instalar dependÃªncias

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` com as informaÃ§Ãµes do seu banco PostgreSQL:

```ini
DB_HOST=localhost
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=teste_fidelity

UPDATE_EXISTING_RECORDS=false  # ou true para atualizar registros existentes
```

### 3. Criar as tabelas no banco

```bash
python scripts/create_tables.py
```

### 4. (Opcional) Inserir dados mock para teste

```bash
python scripts/insert_mock_data.py
```

### 5. Executar o scraping
- No arquivo main.py vocÃª pode alterar o meio de pesquisa se necessÃ¡rio
![alt text](image.png)
```bash
python main.py
```

---

## Estrutura de Dados

### ğŸ”¹ Tabela `pesquisa`

Representa os dados da pessoa consultada (nome, CPF, RG, data de nascimento etc.).

### ğŸ”¹ Tabela `pesquisa_spv`

Registra o resultado da consulta feita (nada consta, consta criminal, consta cÃ­vel, erro).

### ğŸ”¹ Tabela `lote` e `lote_pesquisa`

Permitem agrupar mÃºltiplas pesquisas em "lotes" para controle e rastreabilidade.

### ğŸ”¹ Tabela `estado`

Armazena os estados/UF das origens dos processos.

### ğŸ”¹ Tabela `servico`

Define o tipo de consulta associada Ã  pesquisa (ex: TJSP).

---

## Sistema de Backup

* Toda vez que houver falha ao salvar no banco, os dados da pesquisa sÃ£o exportados em `.xlsx` no diretÃ³rio raiz.
* O nome do arquivo segue o padrÃ£o: `backup_YYYY-MM-DD_HH-MM-SS.xlsx`.
* Na prÃ³xima execuÃ§Ã£o, o sistema verifica a existÃªncia desses backups e os processa **antes** de iniciar novo scraping.
* ApÃ³s processar os backups com sucesso, o sistema os remove automaticamente.

---

## Design Robusto e Profissional

Este projeto foi desenvolvido com foco em:

* Boas prÃ¡ticas de engenharia de dados
* OrganizaÃ§Ã£o modular e desacoplada (models, services, repositories, utils)
* TolerÃ¢ncia a falhas com rotas de fallback
* Performance com scraping paginado e seletivo
* Logs e mensagens compreensÃ­veis em CLI

---